# ğŸª„ Lumos
<p align="center">
  <a href="">
    <img src="https://img.shields.io/badge/ğŸŒ-Website-red">
  </a>
  <a href="">
    <img src="https://img.shields.io/badge/ğŸ“-Paper-blue">
  </a>
  <a href="">
    <img src="https://img.shields.io/badge/ğŸ¤—-Data-orange">
  </a>
  <a href="">
    <img src="https://img.shields.io/badge/ğŸ¤—-Model-green">
  </a> 
</p>

We introduce ğŸª„**Lumos**, Language Agents with **Unified** Formats, **Modular** Design, and **Open-Source** LLMs. **Lumos** unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. 

**Lumos** has following features:
* ğŸ§© **Modular Architecture**:
  - **Lumos** consists planning, grounding, and execution modules built based on open LLMs such as LLAMA-2.
* ğŸŒ **Diverse Training Data**:
  - **Lumos** is trained with ~40K high-quality annotations from ground-truth reasoning steps in existing benchmarks with GPT-4. 
* ğŸš€ **Competitive Performance**:
  - ğŸš€ **Lumos** outperforms **GPT-4/3.5-based** agents on complex QA and web agent tasks, and larger open agents on maths tasks.
  - ğŸš€ **Lumos** performs better than open agent baseline formulations including **chain-of-thoughts** and **unmodularized** training.
  - ğŸš€ **Lumos** surpasses larger open LLM agents and domain-specific agents on an unseen task, WebShop.

## ğŸ”¥ News
- **[2023, Oct ]** We release the important items for training and evaluating **Lumos**:
  - ğŸ’» **Lumos** code for annotation generation, training and evaluation
  - ğŸ¤— **Lumos** checkpoints with 7B model size
  - ğŸ¤— **Lumos** training annotations and their raw data
 
## ğŸ§© Architecture


## Training Paradigm
